{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "f0928fd5",
      "metadata": {
        "id": "f0928fd5"
      },
      "source": [
        "# Deploying AI\n",
        "## Assignment 1: Evaluating Summaries"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8f3586e4",
      "metadata": {
        "id": "8f3586e4"
      },
      "source": [
        "A key application of LLMs is to summarize documents. In this assignment, we will not only summarize documents, but also evaluate the quality of the summary and return the results using structured outputs."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "609f2fa2",
      "metadata": {
        "id": "609f2fa2"
      },
      "source": [
        "**Instructions:** please complete the sections below stating any relevant decisions that you have made and showing the code substantiating your solution."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "604f0601",
      "metadata": {
        "id": "604f0601"
      },
      "source": [
        "## Select a Document\n",
        "\n",
        "Please select one out of the following articles:\n",
        "\n",
        "+ [Managing Oneself, by Peter Druker](https://www.thecompleteleader.org/sites/default/files/imce/Managing%20Oneself_Drucker_HBR.pdf)  (PDF)\n",
        "+ [The GenAI Divide: State of AI in Business 2025](https://www.artificialintelligence-news.com/wp-content/uploads/2025/08/ai_report_2025.pdf) (PDF)\n",
        "+ [What is Noise?, by Alex Ross](https://www.newyorker.com/magazine/2024/04/22/what-is-noise) (Web)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2c125d1e",
      "metadata": {
        "id": "2c125d1e"
      },
      "source": [
        "# Load Secrets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b8dbcc48",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b8dbcc48",
        "outputId": "293c5c70-1243-4399-86c4-0c78f1ace3fd"
      },
      "outputs": [],
      "source": [
        "%load_ext dotenv\n",
        "%dotenv ../05_src/.secrets"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7b036115",
      "metadata": {
        "id": "7b036115"
      },
      "source": [
        "## Load Document\n",
        "\n",
        "Depending on your choice, you can consult the appropriate set of functions below. Make sure that you understand the content that is extracted and if you need to perform any additional operations (like joining page content).\n",
        "\n",
        "### PDF\n",
        "\n",
        "You can load a PDF by following the instructions in [LangChain's documentation](https://docs.langchain.com/oss/python/langchain/knowledge-base#loading-documents). Notice that the output of the loading procedure is a collection of pages. You can join the pages by using the code below.\n",
        "\n",
        "```python\n",
        "document_text = \"\"\n",
        "for page in docs:\n",
        "    document_text += page.page_content + \"\\n\"\n",
        "```\n",
        "\n",
        "### Web\n",
        "\n",
        "LangChain also provides a set of web loaders, including the [WebBaseLoader](https://docs.langchain.com/oss/python/integrations/document_loaders/web_base). You can use this function to load web pages."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e612b8d9",
      "metadata": {},
      "source": [
        "Web was selected"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3bb58dec",
      "metadata": {},
      "source": [
        "For Colab only"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e35d9654",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Set OpenAI key using Colab (for Colab)\n",
        "'''\n",
        "import os\n",
        "from google.colab import userdata\n",
        "os.environ[\"OPENAI_API_KEY\"] = userdata.get(\"OpenAI\")\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "amzeTkp2sr9E",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "amzeTkp2sr9E",
        "outputId": "8b3d9cf5-eac4-4ddb-e403-0185bda67d19"
      },
      "outputs": [],
      "source": [
        "#!pip list | grep -E \"langchain|openai|langgraph\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "60KHqwLcq0DK",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "60KHqwLcq0DK",
        "outputId": "f4307e97-9b84-408c-da14-fffcc9733fde"
      },
      "outputs": [],
      "source": [
        "# Install libraries for Colab usage\n",
        "#!pip install langchain-community"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "256159db",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "256159db",
        "outputId": "e007dbd4-d9b0-440d-8816-2b2da56ef74f"
      },
      "outputs": [],
      "source": [
        "# Load the document via langchain\n",
        "from langchain_community.document_loaders import WebBaseLoader\n",
        "\n",
        "url = \"https://www.newyorker.com/magazine/2024/04/22/what-is-noise\"\n",
        "\n",
        "loader = WebBaseLoader(web_paths=[url])\n",
        "docs = loader.load()\n",
        "\n",
        "print(f\"Loaded {len(docs)} document(s)\")\n",
        "print(docs[0].page_content[:1000])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6951b9f3",
      "metadata": {
        "id": "6951b9f3"
      },
      "source": [
        "## Generation Task\n",
        "\n",
        "Using the OpenAI SDK, please create a **structured outut** with the following specifications:\n",
        "\n",
        "+ Use a model that is NOT in the GPT-5 family.\n",
        "+ Output should be a Pydantic BaseModel object. The fields of the object should be:\n",
        "\n",
        "    - Author\n",
        "    - Title\n",
        "    - Relevance: a statement, no longer than one paragraph, that explains why is this article relevant for an AI professional in their professional development.\n",
        "    - Summary: a concise and succinct summary no longer than 1000 tokens.\n",
        "    - Tone: the tone used to produce the summary (see below).\n",
        "    - InputTokens: number of input tokens (obtain this from the response object).\n",
        "    - OutputTokens: number of tokens in output (obtain this from the response object).\n",
        "       \n",
        "+ The summary should be written using a specific and distinguishable tone, for example,  \"Victorian English\", \"African-American Vernacular English\", \"Formal Academic Writing\", \"Bureaucratese\" ([the obscure language of beaurocrats](https://tumblr.austinkleon.com/post/4836251885)), \"Legalese\" (legal language), or any other distinguishable style of your preference. Make sure that the style is something you can identify.\n",
        "+ In your implementation please make sure to use the following:\n",
        "\n",
        "    - Instructions and context should be stored separately and the context should be added dynamically. Do not hard-code your prompt, instead use formatted strings or an equivalent technique.\n",
        "    - Use the developer (instructions) prompt and the user prompt.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e02fea15",
      "metadata": {
        "id": "e02fea15"
      },
      "outputs": [],
      "source": [
        "# Load libraries\n",
        "import os\n",
        "import json\n",
        "from typing import Literal\n",
        "from pydantic import BaseModel, Field\n",
        "from openai import OpenAI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "qB9E0uzw01wK",
      "metadata": {
        "id": "qB9E0uzw01wK"
      },
      "outputs": [],
      "source": [
        "# Upgrade OpenAI SDK\n",
        "'''\n",
        "!pip install -U openai\n",
        "from openai import OpenAI\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "EIuPs7aAzB9F",
      "metadata": {
        "id": "EIuPs7aAzB9F"
      },
      "outputs": [],
      "source": [
        "class ArticleBrief(BaseModel):\n",
        "    Author: str\n",
        "    Title: str\n",
        "    Relevance: str\n",
        "    Summary: str\n",
        "    Tone: str\n",
        "    InputTokens: int\n",
        "    OutputTokens: int\n",
        "\n",
        "    model_config = {\n",
        "        \"extra\": \"forbid\"\n",
        "    }\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "snnUg_dG15Ba",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "snnUg_dG15Ba",
        "outputId": "b995e4ea-1e74-44de-ba6b-5de4d8aa35ea"
      },
      "outputs": [],
      "source": [
        "url = \"https://www.newyorker.com/magazine/2024/04/22/what-is-noise\"\n",
        "\n",
        "loader = WebBaseLoader(web_paths=[url])\n",
        "docs = loader.load()\n",
        "\n",
        "article_text = \"\\n\\n\".join(d.page_content for d in docs).strip()\n",
        "print(article_text[:800])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "sMdRQ7MJ196l",
      "metadata": {
        "id": "sMdRQ7MJ196l"
      },
      "outputs": [],
      "source": [
        "DEVELOPER_INSTRUCTIONS = \"\"\"\n",
        "You are a precise summarization system for AI professionals.\n",
        "\n",
        "Return ONLY valid JSON matching the provided schema.\n",
        "Do NOT include token counts.\n",
        "Do NOT include extra keys.\n",
        "\n",
        "Constraints:\n",
        "- Relevance must be at most one paragraph.\n",
        "- Summary must be under 1000 tokens.\n",
        "- The summary must strongly reflect the requested tone.\n",
        "\"\"\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "OKEvsdTXAI2j",
      "metadata": {
        "id": "OKEvsdTXAI2j"
      },
      "outputs": [],
      "source": [
        "TONE = \"Bureaucratese\"\n",
        "\n",
        "USER_PROMPT_TEMPLATE = \"\"\"\n",
        "Summarize the following article for AI professional development.\n",
        "\n",
        "Required tone: {tone}\n",
        "\n",
        "Article:\n",
        "{article}\n",
        "\"\"\"\n",
        "\n",
        "user_prompt = USER_PROMPT_TEMPLATE.format(\n",
        "    tone=TONE,\n",
        "    article=article_text\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "zUUVjKZ12FPo",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zUUVjKZ12FPo",
        "outputId": "b51097fb-29d0-4fe0-dead-34180e80a769"
      },
      "outputs": [],
      "source": [
        "# Cell 5 ‚Äî Responses API call with Structured Outputs using text.format (THIS fixes your error)\n",
        "\n",
        "client = OpenAI(api_key=os.environ.get(\"OPENAI_API_KEY\"))\n",
        "\n",
        "MODEL = \"gpt-4o-mini\"  # NOT GPT-5 family; supports structured outputs\n",
        "\n",
        "schema = ArticleBrief.model_json_schema()\n",
        "# Remove token fields from model generation\n",
        "schema[\"properties\"].pop(\"InputTokens\")\n",
        "schema[\"properties\"].pop(\"OutputTokens\")\n",
        "schema[\"required\"].remove(\"InputTokens\")\n",
        "schema[\"required\"].remove(\"OutputTokens\")\n",
        "\n",
        "schema[\"additionalProperties\"] = False\n",
        "\n",
        "resp = client.responses.create(\n",
        "    model=MODEL,\n",
        "    input=[\n",
        "        {\"role\": \"developer\", \"content\": DEVELOPER_INSTRUCTIONS.strip()},\n",
        "        {\"role\": \"user\", \"content\": user_prompt},\n",
        "    ],\n",
        "    text={\n",
        "        \"format\": {\n",
        "            \"type\": \"json_schema\",\n",
        "            \"name\": \"ArticleBrief\",\n",
        "            \"strict\": True,\n",
        "            \"schema\": schema,\n",
        "        }\n",
        "    },\n",
        ")\n",
        "\n",
        "resp\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d1d4ZkwWAh7n",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d1d4ZkwWAh7n",
        "outputId": "65cbdca2-ba13-4279-a39f-7ad7cd611495"
      },
      "outputs": [],
      "source": [
        "data = json.loads(resp.output_text)\n",
        "\n",
        "# Inject REAL token usage from API\n",
        "data[\"InputTokens\"] = resp.usage.input_tokens\n",
        "data[\"OutputTokens\"] = resp.usage.output_tokens\n",
        "\n",
        "brief = ArticleBrief(**data)\n",
        "\n",
        "brief\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "YSX3y0rfAz9Y",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YSX3y0rfAz9Y",
        "outputId": "1fd13926-d5cd-4d8f-938b-a5046be3d40e"
      },
      "outputs": [],
      "source": [
        "print(\"Title:\", brief.Title)\n",
        "print(\"Author:\", brief.Author)\n",
        "print(\"Tone:\", brief.Tone)\n",
        "print(\"Tokens:\", brief.InputTokens, \"input /\", brief.OutputTokens, \"output\")\n",
        "print(\"\\nRelevance:\\n\", brief.Relevance)\n",
        "print(\"\\nSummary Preview:\\n\", brief.Summary[:1200])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ec1e63f8",
      "metadata": {
        "id": "ec1e63f8"
      },
      "source": [
        "# Evaluate the Summary\n",
        "\n",
        "Use the DeepEval library to evaluate the **summary** as follows:\n",
        "\n",
        "+ Summarization Metric:\n",
        "\n",
        "    - Use the [Summarization metric](https://deepeval.com/docs/metrics-summarization) with a **bespoke** set of assessment questions.\n",
        "    - Please use, at least, five assessment questions.\n",
        "\n",
        "+ G-Eval metrics:\n",
        "\n",
        "    - In addition to the standard summarization metric above, please implement three evaluation metrics:\n",
        "    \n",
        "        - [Coherence or clarity](https://deepeval.com/docs/metrics-llm-evals#coherence)\n",
        "        - [Tonality](https://deepeval.com/docs/metrics-llm-evals#tonality)\n",
        "        - [Safety](https://deepeval.com/docs/metrics-llm-evals#safety)\n",
        "\n",
        "    - For each one of the metrics above, implement five assessment questions.\n",
        "\n",
        "+ The output should be structured and contain one key-value pair to report the score and another pair to report the explanation:\n",
        "\n",
        "    - SummarizationScore\n",
        "    - SummarizationReason\n",
        "    - CoherenceScore\n",
        "    - CoherenceReason\n",
        "    - ..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "99560b73",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "99560b73",
        "outputId": "0a0d8fad-ff96-4fce-9152-b49188fa2067"
      },
      "outputs": [],
      "source": [
        "#!pip install -U deepeval"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "_STH_pyLBykI",
      "metadata": {
        "id": "_STH_pyLBykI"
      },
      "outputs": [],
      "source": [
        "from deepeval.metrics import SummarizationMetric, GEval\n",
        "from deepeval.test_case import LLMTestCase, LLMTestCaseParams\n",
        "import json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "J6aSntsBB8UH",
      "metadata": {
        "id": "J6aSntsBB8UH"
      },
      "outputs": [],
      "source": [
        "original_text = article_text\n",
        "generated_summary = brief.Summary\n",
        "requested_tone = brief.Tone"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "FnQ3o_uhC-CW",
      "metadata": {
        "id": "FnQ3o_uhC-CW"
      },
      "outputs": [],
      "source": [
        "test_case = LLMTestCase(\n",
        "    input=original_text,\n",
        "    actual_output=generated_summary,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "WN2l_9X0CBAH",
      "metadata": {
        "id": "WN2l_9X0CBAH"
      },
      "outputs": [],
      "source": [
        "summarization_metric = SummarizationMetric(\n",
        "    threshold=0.4,\n",
        "    assessment_questions=[\n",
        "        \"Does the summary accurately capture the main thesis of the article?\",\n",
        "        \"Does the summary include the most important supporting ideas?\",\n",
        "        \"Does the summary avoid introducing information not present in the article?\",\n",
        "        \"Is the summary concise while preserving essential meaning?\",\n",
        "        \"Does the summary reflect the conceptual complexity of the article?\"\n",
        "    ]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "FPXlnMdBCJJz",
      "metadata": {
        "id": "FPXlnMdBCJJz"
      },
      "outputs": [],
      "source": [
        "coherence_metric = GEval(\n",
        "    name=\"Coherence\",\n",
        "    criteria=\"Assess clarity, logical flow, organization, and readability of the summary.\",\n",
        "    evaluation_params=[LLMTestCaseParams.ACTUAL_OUTPUT],\n",
        "    evaluation_steps=[\n",
        "        \"Check whether the summary has a clear structure (beginning, middle, end).\",\n",
        "        \"Verify that ideas progress logically without abrupt jumps.\",\n",
        "        \"Assess whether sentences are clear, grammatical, and easy to parse.\",\n",
        "        \"Identify redundancies or repeated points that reduce clarity.\",\n",
        "        \"Decide whether the overall summary is easy to follow for a professional reader.\",\n",
        "    ],\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "XrdjihrKCvlJ",
      "metadata": {
        "id": "XrdjihrKCvlJ"
      },
      "outputs": [],
      "source": [
        "tonality_metric = GEval(\n",
        "    name=\"Tonality\",\n",
        "    criteria=f\"Assess whether the summary is written in a clearly distinguishable '{requested_tone}' style and maintains it consistently.\",\n",
        "    evaluation_params=[LLMTestCaseParams.ACTUAL_OUTPUT],\n",
        "    evaluation_steps=[\n",
        "        f\"Determine whether the summary‚Äôs diction and phrasing match '{requested_tone}'.\",\n",
        "        \"Check for consistent register (formal/official vs casual/neutral) throughout.\",\n",
        "        \"Look for distinctive stylistic markers that make the tone identifiable.\",\n",
        "        \"Verify the tone does not drift into generic academic or neutral exposition.\",\n",
        "        \"Judge whether the tone is sustained from start to finish.\",\n",
        "    ],\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "RtcXoqfoCz_z",
      "metadata": {
        "id": "RtcXoqfoCz_z"
      },
      "outputs": [],
      "source": [
        "safety_metric = GEval(\n",
        "    name=\"Safety\",\n",
        "    criteria=\"Assess whether the summary is safe and professionally appropriate (no harmful instructions, hate/harassment, explicit sexual content, or dangerous guidance).\",\n",
        "    evaluation_params=[LLMTestCaseParams.ACTUAL_OUTPUT],\n",
        "    evaluation_steps=[\n",
        "        \"Check for any hate, harassment, or discriminatory content.\",\n",
        "        \"Check for any sexual content that is explicit or inappropriate.\",\n",
        "        \"Check for instructions or facilitation of wrongdoing or dangerous activity.\",\n",
        "        \"Check for self-harm content or encouragement of self-harm.\",\n",
        "        \"Confirm the overall content remains professional and non-harmful.\",\n",
        "    ],\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fun61W3wC55W",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34,
          "referenced_widgets": [
            "91af50045a534a2fa784ad77fbf84412",
            "fb3250858cc546fcb802075f7e2cf5eb",
            "f7bee0c3ac924979b4c1f5bcf9a11488",
            "14ab072173174f51bb755b1d147c59d2",
            "71b16b38c02641d883a218e078d48bfd",
            "cf5f1bbcb4ff4180bcba98de94b6a7d6",
            "0ba6b7dbb4924c31bdd245ccdfe288ae",
            "11bc6ceb106941418485b2b296f2240f"
          ]
        },
        "id": "fun61W3wC55W",
        "outputId": "a17d13c4-2bda-44fd-b2f2-f4fbeb5001af"
      },
      "outputs": [],
      "source": [
        "summarization_metric.measure(test_case)\n",
        "coherence_metric.measure(test_case)\n",
        "tonality_metric.measure(test_case)\n",
        "safety_metric.measure(test_case)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "uumQ_EimDR4-",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uumQ_EimDR4-",
        "outputId": "da5a8ecc-62f2-4a96-c954-fb0def74695b"
      },
      "outputs": [],
      "source": [
        "results = {\n",
        "    \"SummarizationScore\": summarization_metric.score,\n",
        "    \"SummarizationReason\": summarization_metric.reason,\n",
        "\n",
        "    \"CoherenceScore\": coherence_metric.score,\n",
        "    \"CoherenceReason\": coherence_metric.reason,\n",
        "\n",
        "    \"TonalityScore\": tonality_metric.score,\n",
        "    \"TonalityReason\": tonality_metric.reason,\n",
        "\n",
        "    \"SafetyScore\": safety_metric.score,\n",
        "    \"SafetyReason\": safety_metric.reason,\n",
        "}\n",
        "\n",
        "results"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c000bb60",
      "metadata": {
        "id": "c000bb60"
      },
      "source": [
        "# Enhancement\n",
        "\n",
        "Of course, evaluation is important, but we want our system to self-correct.  \n",
        "\n",
        "+ Use the context, summary, and evaluation that you produced in the steps above to create a new prompt that enhances the summary.\n",
        "+ Evaluate the new summary using the same function.\n",
        "+ Report your results. Did you get a better output? Why? Do you think these controls are enough?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4cf01e4f",
      "metadata": {
        "id": "4cf01e4f"
      },
      "outputs": [],
      "source": [
        "improvement_prompt = f\"\"\"\n",
        "You are tasked with improving a previously generated summary.\n",
        "\n",
        "ORIGINAL ARTICLE:\n",
        "{article_text}\n",
        "\n",
        "PREVIOUS SUMMARY:\n",
        "{brief.Summary}\n",
        "\n",
        "EVALUATION RESULTS:\n",
        "Summarization Score: {results[\"SummarizationScore\"]}\n",
        "Summarization Reason: {results[\"SummarizationReason\"]}\n",
        "\n",
        "Coherence Score: {results[\"CoherenceScore\"]}\n",
        "Coherence Reason: {results[\"CoherenceReason\"]}\n",
        "\n",
        "Tonality Score: {results[\"TonalityScore\"]}\n",
        "Tonality Reason: {results[\"TonalityReason\"]}\n",
        "\n",
        "Safety Score: {results[\"SafetyScore\"]}\n",
        "Safety Reason: {results[\"SafetyReason\"]}\n",
        "\n",
        "INSTRUCTIONS:\n",
        "1. Improve factual completeness and alignment with the article.\n",
        "2. Address weaknesses identified in the evaluation reasons.\n",
        "3. Strongly enforce the requested tone: {brief.Tone}.\n",
        "4. Keep summary under 1000 tokens.\n",
        "5. Preserve conceptual nuance and complexity.\n",
        "\n",
        "Return ONLY the improved summary text.\n",
        "\"\"\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Zc0EQPBYEY0H",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "Zc0EQPBYEY0H",
        "outputId": "f707e5ea-3203-464a-d889-f7e5684c6cb7"
      },
      "outputs": [],
      "source": [
        "resp_improved = client.responses.create(\n",
        "    model=\"gpt-4o-mini\",\n",
        "    input=improvement_prompt\n",
        ")\n",
        "\n",
        "improved_summary = resp_improved.output_text.strip()\n",
        "\n",
        "print(improved_summary[:1200])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4bf1yhS4EoR-",
      "metadata": {
        "id": "4bf1yhS4EoR-"
      },
      "outputs": [],
      "source": [
        "new_test_case = LLMTestCase(\n",
        "    input=article_text,\n",
        "    actual_output=improved_summary\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "O0F8UU9MEsro",
      "metadata": {
        "id": "O0F8UU9MEsro"
      },
      "outputs": [],
      "source": [
        "summarization_metric.measure(new_test_case)\n",
        "coherence_metric.measure(new_test_case)\n",
        "tonality_metric.measure(new_test_case)\n",
        "safety_metric.measure(new_test_case)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5qLVH8HqE7H2",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5qLVH8HqE7H2",
        "outputId": "b368c190-c608-43c2-93e7-f791bdbd7b38"
      },
      "outputs": [],
      "source": [
        "new_results = {\n",
        "    \"SummarizationScore\": summarization_metric.score,\n",
        "    \"SummarizationReason\": summarization_metric.reason,\n",
        "\n",
        "    \"CoherenceScore\": coherence_metric.score,\n",
        "    \"CoherenceReason\": coherence_metric.reason,\n",
        "\n",
        "    \"TonalityScore\": tonality_metric.score,\n",
        "    \"TonalityReason\": tonality_metric.reason,\n",
        "\n",
        "    \"SafetyScore\": safety_metric.score,\n",
        "    \"SafetyReason\": safety_metric.reason,\n",
        "}\n",
        "\n",
        "new_results"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "14d0de25",
      "metadata": {
        "id": "14d0de25"
      },
      "source": [
        "My Comments:\n",
        "The evaluation results are mixed and somewhat surprising. While I agree with the high Coherence (0.90) and perfect Safety (1.0) scores, I disagree with the SummarizationScore of 0.00, and I think it warrants closer scrutiny‚Äîparticularly in light of the chosen threshold (0.7).\n",
        "\n",
        "A score of 0.00 suggests total failure under the metric. That implies the summary is either completely inaccurate, hallucinated, or fundamentally misaligned with the source text. However, based on my own inspection of the summary:\n",
        "\n",
        "The core thesis (noise as a multifaceted concept with cultural, technological, and artistic dimensions) was captured.\n",
        "\n",
        "The summary referenced the duality of noise (negative vs. expressive/artistic), which is central to the article.\n",
        "\n",
        "It maintained conceptual coherence with the original narrative arc.\n",
        "\n",
        "A more plausible outcome would be a low-but-nonzero score (e.g., 0.4‚Äì0.6) indicating partial misalignment.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "98e81f47",
      "metadata": {
        "id": "98e81f47"
      },
      "source": [
        "\n",
        "# Submission Information\n",
        "\n",
        "üö® **Please review our [Assignment Submission Guide](https://github.com/UofT-DSI/onboarding/blob/main/onboarding_documents/submissions.md)** üö® for detailed instructions on how to format, branch, and submit your work. Following these guidelines is crucial for your submissions to be evaluated correctly.\n",
        "\n",
        "## Submission Parameters\n",
        "\n",
        "- The Submission Due Date is indicated in the [readme](../README.md#schedule) file.\n",
        "- The branch name for your repo should be: assignment-1\n",
        "- What to submit for this assignment:\n",
        "    + This Jupyter Notebook (assignment_1.ipynb) should be populated and should be the only change in your pull request.\n",
        "- What the pull request link should look like for this assignment: `https://github.com/<your_github_username>/production/pull/<pr_id>`\n",
        "    + Open a private window in your browser. Copy and paste the link to your pull request into the address bar. Make sure you can see your pull request properly. This helps the technical facilitator and learning support staff review your submission easily.\n",
        "\n",
        "## Checklist\n",
        "\n",
        "+ Created a branch with the correct naming convention.\n",
        "+ Ensured that the repository is public.\n",
        "+ Reviewed the PR description guidelines and adhered to them.\n",
        "+ Verify that the link is accessible in a private browser window.\n",
        "\n",
        "If you encounter any difficulties or have questions, please don't hesitate to reach out to our team via our Slack. Our Technical Facilitators and Learning Support staff are here to help you navigate any challenges.\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0ba6b7dbb4924c31bdd245ccdfe288ae": {
          "model_module": "@jupyter-widgets/output",
          "model_module_version": "1.0.0",
          "model_name": "OutputModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/output",
            "_model_module_version": "1.0.0",
            "_model_name": "OutputModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/output",
            "_view_module_version": "1.0.0",
            "_view_name": "OutputView",
            "layout": "IPY_MODEL_11bc6ceb106941418485b2b296f2240f",
            "msg_id": "",
            "outputs": [
              {
                "data": {
                  "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">‚†ô</span> <span style=\"color: #3a3a3a; text-decoration-color: #3a3a3a\">‚îÅ‚îÅ‚îÅ‚îÅ</span> ‚ú® You're running DeepEval's latest <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Safety [GEval] Metric</span>! <span style=\"color: #374151; text-decoration-color: #374151\">(using gpt-4.1, strict=False, async_mode=True)...</span>\n</pre>\n",
                  "text/plain": "\u001b[38;2;106;0;255m‚†ô\u001b[0m \u001b[38;5;237m‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m ‚ú® You're running DeepEval's latest \u001b[38;2;106;0;255mSafety [GEval] Metric\u001b[0m! \u001b[38;2;55;65;81m(using gpt-4.1, strict=False, async_mode=True)...\u001b[0m\n"
                },
                "metadata": {},
                "output_type": "display_data"
              }
            ]
          }
        },
        "11bc6ceb106941418485b2b296f2240f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "14ab072173174f51bb755b1d147c59d2": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "71b16b38c02641d883a218e078d48bfd": {
          "model_module": "@jupyter-widgets/output",
          "model_module_version": "1.0.0",
          "model_name": "OutputModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/output",
            "_model_module_version": "1.0.0",
            "_model_name": "OutputModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/output",
            "_view_module_version": "1.0.0",
            "_view_name": "OutputView",
            "layout": "IPY_MODEL_cf5f1bbcb4ff4180bcba98de94b6a7d6",
            "msg_id": "",
            "outputs": [
              {
                "data": {
                  "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">‚†ã</span> <span style=\"color: #3a3a3a; text-decoration-color: #3a3a3a\">‚îÅ‚îÅ</span> ‚ú® You're running DeepEval's latest <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Tonality [GEval] Metric</span>! <span style=\"color: #374151; text-decoration-color: #374151\">(using gpt-4.1, strict=False, async_mode=True)...</span>\n</pre>\n",
                  "text/plain": "\u001b[38;2;106;0;255m‚†ã\u001b[0m \u001b[38;5;237m‚îÅ‚îÅ\u001b[0m ‚ú® You're running DeepEval's latest \u001b[38;2;106;0;255mTonality [GEval] Metric\u001b[0m! \u001b[38;2;55;65;81m(using gpt-4.1, strict=False, async_mode=True)...\u001b[0m\n"
                },
                "metadata": {},
                "output_type": "display_data"
              }
            ]
          }
        },
        "91af50045a534a2fa784ad77fbf84412": {
          "model_module": "@jupyter-widgets/output",
          "model_module_version": "1.0.0",
          "model_name": "OutputModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/output",
            "_model_module_version": "1.0.0",
            "_model_name": "OutputModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/output",
            "_view_module_version": "1.0.0",
            "_view_name": "OutputView",
            "layout": "IPY_MODEL_fb3250858cc546fcb802075f7e2cf5eb",
            "msg_id": "",
            "outputs": [
              {
                "data": {
                  "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">‚†ß</span> <span style=\"color: #3a3a3a; text-decoration-color: #3a3a3a\">‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ</span> ‚ú® You're running DeepEval's latest <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Summarization Metric</span>! <span style=\"color: #374151; text-decoration-color: #374151\">(using gpt-4.1, strict=False, async_mode=True)...</span>\n</pre>\n",
                  "text/plain": "\u001b[38;2;106;0;255m‚†ß\u001b[0m \u001b[38;5;237m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m ‚ú® You're running DeepEval's latest \u001b[38;2;106;0;255mSummarization Metric\u001b[0m! \u001b[38;2;55;65;81m(using gpt-4.1, strict=False, async_mode=True)...\u001b[0m\n"
                },
                "metadata": {},
                "output_type": "display_data"
              }
            ]
          }
        },
        "cf5f1bbcb4ff4180bcba98de94b6a7d6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f7bee0c3ac924979b4c1f5bcf9a11488": {
          "model_module": "@jupyter-widgets/output",
          "model_module_version": "1.0.0",
          "model_name": "OutputModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/output",
            "_model_module_version": "1.0.0",
            "_model_name": "OutputModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/output",
            "_view_module_version": "1.0.0",
            "_view_name": "OutputView",
            "layout": "IPY_MODEL_14ab072173174f51bb755b1d147c59d2",
            "msg_id": "",
            "outputs": [
              {
                "data": {
                  "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">‚†á</span> <span style=\"color: #3a3a3a; text-decoration-color: #3a3a3a\">‚îÅ</span> ‚ú® You're running DeepEval's latest <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Coherence [GEval] Metric</span>! <span style=\"color: #374151; text-decoration-color: #374151\">(using gpt-4.1, strict=False, async_mode=True)...</span>\n</pre>\n",
                  "text/plain": "\u001b[38;2;106;0;255m‚†á\u001b[0m \u001b[38;5;237m‚îÅ\u001b[0m ‚ú® You're running DeepEval's latest \u001b[38;2;106;0;255mCoherence [GEval] Metric\u001b[0m! \u001b[38;2;55;65;81m(using gpt-4.1, strict=False, async_mode=True)...\u001b[0m\n"
                },
                "metadata": {},
                "output_type": "display_data"
              }
            ]
          }
        },
        "fb3250858cc546fcb802075f7e2cf5eb": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
